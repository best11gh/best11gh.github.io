---
title:  "자연어 처리 스터디 1주차"
excerpt: "필기 4일, 실기 2주 컷"

categories:
  - NL

toc: true
toc_sticky: true
 
date: 2023-03-29
last_modified_at: 2023-03-29
---


**텍스트 전처리**
- 풀고자 하는 문제의 용도에 맞게 텍스트를 사전에 처리하는 작업이다. 제대로 전처리하지 않으면 자연어 처리 기법이 제대로 동작하지 않는다.

- 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자 하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)를 해야 한다. 


# 토큰화

- 주어진 코퍼스에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화라고 한다. 
    - 토큰의 단위가 상황에 따라 다르지만, 보통 의미 있는 단위로 토큰을 정의한다.



## 단어 토큰화
- 토큰의 기준을 단어로 하는 경우, 단어 토큰화라고 한다. 
- 다만, 여기서 단어(word)는 단어 단위 외에도 단어구, 의미를 갖는 문자열로도 간주한다.
- ex) 구두점과 같은 문자를 제외하는 토큰화 작업
    ```
    input : Time is an illusion. Lunchtime double so!

    output : "Time", "is", "an", "illustion", "Lunchtime", "double", "so"
    ```
    - 구두점을 지운 뒤, 띄어쓰기를 기준으로 잘라냄

- 구두점이나 특수문자를 전부 제거하면 토큰이 의미를 잃어버리는 경우가 발생하기도 하니 주의해야한다.

- 띄어쓰기 단위로 자르면 사실상 단어 토큰이 구분되는 영어와 달리, 한국어는 띄어쓰기만으로는 단어 토큰을 구분하기 어렵다


### 아포스트로피를(')가 들어가있는 단어의 경우


**1. word_tokenize 사용**
- 


**2. WordPunctTokenizer 사용**


### 고려해야 할 사항

1) 구두점이나 특수 문자를 단순 제외해서는 안된다.
- 마침표와 같은 경우는 문장의 경계를 알 수 있는데 도움이 되므로 단어를 뽑아낼 때, 마침표를 제외하지 않을 수도 있다.

- 단어 자체에 구두점을 가지고 있을 수도 있다.
    ex) m.p.h, Ph.d, 45.55, 01/02/06

2) 줄임말과 단어 내에 띄어쓰기가 있는 경우
- ex) what're, I'm, New York,  rock 'n' roll
    - re이나 m을 접어라고 한다. 

- Penn Treebank
    - 규칙 1 : 하이푼으로 구성된 단어는 하나로 유지한다.
    - 규칙 2 :  doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.

    - ex)



## 문장 토큰화
- 토큰의 단위가 문장인 경우, 문장 분류라고도 부른다.
- 사용하는 코퍼스가 어떤 국적의 언어인지, 해당 코퍼스 내에서 특수문자들이 어떻게 사용되고 있는지에 따라서 직접 규칙들을 정의해볼 수도 있다.

- 그러나 갖고 있는 코퍼스 데이터에 오타나, 문자의 구성이 엉망이라면 정해놓은 규칙이 소용이 없을 수도 있어 100% 정확도를 얻는 것은 쉬운 일이 아니다. 


### NLTK 사용 예시

- NLTK에서는 영어 문장의 토큰화를 수행하는 sent_tokenize를 지원하고 있다.



