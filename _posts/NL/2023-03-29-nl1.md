---
title:  "자연어 처리 스터디 1주차"
excerpt: "토큰화, 정제 and 정규화, 어간 추출 and 표제어 추출, 불용어, 정규 표현식"
categories:
  - NL

toc: true
toc_sticky: true
 
date: 2023-03-29
last_modified_at: 2023-03-29
---


**텍스트 전처리**
- 풀고자 하는 문제의 용도에 맞게 텍스트를 사전에 처리하는 작업이다. 제대로 전처리하지 않으면 자연어 처리 기법이 제대로 동작하지 않는다.

- 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자 하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)를 해야 한다. 

---

# 토큰화
- 주어진 코퍼스에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화라고 한다. 
    - 토큰의 단위가 상황에 따라 다르지만, 보통 의미 있는 단위로 토큰을 정의한다.



## 단어 토큰화
- 토큰의 기준을 단어로 하는 경우, 단어 토큰화라고 한다. 

- 구두점과 같은 문자를 제외하는 토큰화 작업
    ```
    input : Time is an illusion. Lunchtime double so!

    output : "Time", "is", "an", "illustion", "Lunchtime", "double", "so"
    ```
    - 구두점을 지운 뒤, 띄어쓰기를 기준으로 잘라냄 
<br>
- 구두점이나 특수문자를 전부 제거하면 토큰이 의미를 잃어버리는 경우가 발생하기도 하니 주의해야한다.




### 아포스트로피를(')가 들어가있는 단어의 경우

```
Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.
```
---

**1. word_tokenize**
![자연어](https://user-images.githubusercontent.com/81560908/228844042-9644c48f-2f9a-45b1-a27a-6dc6d0252cb2.png)

- word_tokenize는 Don't를 Do와 n't로 분리하였으며, 반면 Jone's는 Jone과 's로 분리한 것을 확인할 수 있다.

---

**2. WordPunctTokenizer**
![자연어2](https://user-images.githubusercontent.com/81560908/228844516-e6d94bec-9a50-4ea9-a2e1-eb579dd6d2a5.png)

- WordPunctTokenizer는 구두점을 별도로 분류하는 특징을 갖고 있기때문에, word_tokenize와는 달리 Don't를 Don과 '와 t로 분리하였으며, 이와 마찬가지로 Jone's를 Jone과 '와 s로 분리하였다.

---

**3. text_to_word_sequence**
![자연어3](https://user-images.githubusercontent.com/81560908/228845529-47e03d51-74f0-4d6b-b9e4-6f3d0b645327.png)

- 케라스의 text_to_word_sequence는 기본적으로 모든 알파벳을 소문자로 바꾸면서 마침표나 컴마, 느낌표 등의 구두점을 제거한다. 
- 하지만 don't나 jone's와 같은 경우 아포스트로피는 보존하는 것을 볼 수 있다.

---

**4. Penn Treebank**
- 규칙 1 : 하이푼으로 구성된 단어는 하나로 유지한다.
- 규칙 2 :  doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.

    ```
    Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.
    ```

    ![자연어4](https://user-images.githubusercontent.com/81560908/228846647-68c72946-b10b-4e99-81e5-c00dc199eb9c.png)

    - 결과를 보면, 각각 규칙1과 규칙2에 따라서 home-based는 하나의 토큰으로 취급하고 있으며, dosen't의 경우 does와 n't는 분리되었음을 볼 수 있다.








## 문장 토큰화
- 토큰의 단위가 문장인 경우, 문장 분류라고도 부른다.

**1. sent_tokenize 사용**
```
His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.
```

![image](https://user-images.githubusercontent.com/81560908/228858773-0f7f53ce-1ab8-497a-8934-5e1ab35ada32.png)

```
I am actively looking for Ph.D. students. and you are a Ph.D student.
```

![image](https://user-images.githubusercontent.com/81560908/228861909-09e8087d-2d76-4c78-b4bf-cd1a4728d4eb.png)

- 결과를 보면, 문장 중간에 마침표가 다수 등장하는 경우에도 성공적으로 인식한다.

---

**2. KSS split_sentences 사용**

한국어에 대한 문장 토큰화 도구
```
딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?
```

![image](https://user-images.githubusercontent.com/81560908/228860694-1d1cb001-f2a0-41fb-8659-260393789822.png)

